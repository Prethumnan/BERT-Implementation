{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***STEPS IN BUILDING BERT MODEL***\n",
        "\n",
        "**Tokenization**\n",
        "\n",
        "1. Just like other model, we need to convert the sentences into the tokens (encoded words which will be in the form of numbers)\n",
        "\n",
        "  * Adding special tokens (CLS and SEP). CLS is added in begining and SEP is added at the end.\n",
        "\n",
        "    eg: [CLS] Sentence A [SEP] Sentence B [SEP]\n",
        "\n",
        "  * Then these sentences with special tokens are converted into sequence of numbers.\n",
        "\n",
        "  * Then apply padding to make all tweets (each row) into same length.\n",
        "\n",
        "  The output will be 'input_ids', 'token_type_ids', 'attention_mask'.\n",
        "\n",
        "  * 'input_ids'- These are the actual words which are converted into numbers.\n",
        "\n",
        "  * 'token_type_ids'-  The token_type_ids tensor is used to indicate which tokens belong to the first sentence and which ones belong to the second sentence in a pair of sentences. \n",
        "  \n",
        "  For example, in the sentence pair \"I have a dog. He is friendly.\", the token_type_ids for \"I\" and \"have\" would be 1, and for \"He\" and \"is\" would be 2.\n",
        "\n",
        "  * 'attention_mask' - These are the masked tokens\n",
        "\n",
        "  For example, The [MASK] is playing with his ball.\n",
        "\n",
        "    After masking the above sentence -[1,0,1,1,1,1]\n",
        "\n",
        "  Target output (original masked tokens):\n",
        "  The dog is playing with his ball."
      ],
      "metadata": {
        "id": "tcdOOkFyseAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataloader**\n",
        "\n",
        "We can not load all the inputs (no of tweets) at once. If we do so, we need more memory and it will be computationally expensive.To solve this, we can convert the entire inputs into number of batches\n",
        "\n",
        "Example :If we have 1000 inputs and if we create 10 batches. Then each batch will contain 100 inputs.\n",
        "\n",
        "  * In normal ML model, we will have dependent and indipendent features to train our model. In our case, we have converted only the text into tokens (numbers). So, how to bind the labels (target) with the indipendent feature(text in our case).\n",
        "\n",
        "  * For that we are using `TensorDataset`, it will convert the tensors into dataset or dataframe.we have to give input like 'tokens and labels'.\n",
        "\n",
        "  * Then we are using `DataLoader` to split the inputs into batches"
      ],
      "metadata": {
        "id": "x0rFL5SZ1p7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining model**\n",
        "\n",
        "* Defining optimizer\n",
        "* Defining sheduler\n",
        "\n",
        "**Training**\n",
        "\n",
        "Set model to training mode `model.train()`\n",
        "\n",
        "Iterating from dataloader\n",
        "\n",
        "set gradient to zero  `model.zero_grad()`\n",
        "\n",
        "Load inputs into GPU (else into CPU)\n",
        "\n",
        "Giving input and getting output\n",
        "\n",
        "calculate slope/ derivatinve of loss  `loss.backward`\n",
        "\n",
        "use optimizer `optimizer.step()`\n",
        "\n",
        "use scheduler `scheduler.step()`\n",
        "\n",
        "`\n",
        "        "
      ],
      "metadata": {
        "id": "bSW0snMF5Z0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "PrGFfGZmscem"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmhh3rPOy4vE",
        "outputId": "b1ae067a-eb79-443a-f5d7-55c0a95fe7e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qpJHcJ4_SO9",
        "outputId": "346f2a7b-5c69-4268-acda-1dd8260b77e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kG4RQv4Iuj1S",
        "outputId": "953c6e13-c9ae-43ad-c9c1-b4e28c676fd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      611857364396965889  \\\n",
              "0     614484565059596288   \n",
              "1     614746522043973632   \n",
              "2     614877582664835073   \n",
              "3     611932373039644672   \n",
              "4     611570404268883969   \n",
              "...                  ...   \n",
              "3079  613678555935973376   \n",
              "3080  613294681225621504   \n",
              "3081  615246897670922240   \n",
              "3082  613016084371914753   \n",
              "3083  611566876762640384   \n",
              "\n",
              "     @aandraous @britishmuseum @AndrewsAntonio Merci pour le partage! @openwinemap  \\\n",
              "0     Dorian Gray with Rainbow Scarf #LoveWins (from...                              \n",
              "1     @SelectShowcase @Tate_StIves ... Replace with ...                              \n",
              "2     @Sofabsports thank you for following me back. ...                              \n",
              "3     @britishmuseum @TudorHistory What a beautiful ...                              \n",
              "4     @NationalGallery @ThePoldarkian I have always ...                              \n",
              "...                                                 ...                              \n",
              "3079  MT @AliHaggett: Looking forward to our public ...                              \n",
              "3080                    @britishmuseum Upper arm guard?                              \n",
              "3081           @MrStuchbery @britishmuseum Mesmerising.                              \n",
              "3082  @NationalGallery The 2nd GENOCIDE against #Bia...                              \n",
              "3083  @britishmuseum Experience #battlewaterloo from...                              \n",
              "\n",
              "            nocode  \n",
              "0            happy  \n",
              "1            happy  \n",
              "2            happy  \n",
              "3            happy  \n",
              "4            happy  \n",
              "...            ...  \n",
              "3079         happy  \n",
              "3080        nocode  \n",
              "3081         happy  \n",
              "3082  not-relevant  \n",
              "3083        nocode  \n",
              "\n",
              "[3084 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5260335b-272e-4dfe-af78-5b6c6edb6ddc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>611857364396965889</th>\n",
              "      <th>@aandraous @britishmuseum @AndrewsAntonio Merci pour le partage! @openwinemap</th>\n",
              "      <th>nocode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>614484565059596288</td>\n",
              "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>614746522043973632</td>\n",
              "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>614877582664835073</td>\n",
              "      <td>@Sofabsports thank you for following me back. ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>611932373039644672</td>\n",
              "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>611570404268883969</td>\n",
              "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3079</th>\n",
              "      <td>613678555935973376</td>\n",
              "      <td>MT @AliHaggett: Looking forward to our public ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3080</th>\n",
              "      <td>613294681225621504</td>\n",
              "      <td>@britishmuseum Upper arm guard?</td>\n",
              "      <td>nocode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3081</th>\n",
              "      <td>615246897670922240</td>\n",
              "      <td>@MrStuchbery @britishmuseum Mesmerising.</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3082</th>\n",
              "      <td>613016084371914753</td>\n",
              "      <td>@NationalGallery The 2nd GENOCIDE against #Bia...</td>\n",
              "      <td>not-relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3083</th>\n",
              "      <td>611566876762640384</td>\n",
              "      <td>@britishmuseum Experience #battlewaterloo from...</td>\n",
              "      <td>nocode</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3084 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5260335b-272e-4dfe-af78-5b6c6edb6ddc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5260335b-272e-4dfe-af78-5b6c6edb6ddc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5260335b-272e-4dfe-af78-5b6c6edb6ddc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data=pd.read_csv(\"smile-annotations-final.csv\")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4n4NPFOT5lMD"
      },
      "outputs": [],
      "source": [
        "data.rename(columns={\"nocode\":\"emotion\"},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNBezXsButOG",
        "outputId": "04264c8b-200b-4f4d-9f21-55b4f2b8d82c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nocode               1571\n",
              "happy                1137\n",
              "not-relevant          214\n",
              "angry                  57\n",
              "surprise               35\n",
              "sad                    32\n",
              "happy|surprise         11\n",
              "happy|sad               9\n",
              "disgust|angry           7\n",
              "disgust                 6\n",
              "sad|disgust             2\n",
              "sad|angry               2\n",
              "sad|disgust|angry       1\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data[\"emotion\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V3LOKpcL3RGP"
      },
      "outputs": [],
      "source": [
        "#Considering columns which has only valid emotions\n",
        "df = data[~data.emotion.str.contains('\\|')]\n",
        "df = df[df.emotion != 'nocode']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0rVUloB3kd7",
        "outputId": "b3ac67c5-a248-4575-c178-209ba81a7815"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "happy           1137\n",
              "not-relevant     214\n",
              "angry             57\n",
              "surprise          35\n",
              "sad               32\n",
              "disgust            6\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.emotion.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amRZeV1T4pJw",
        "outputId": "f5f5dcc7-60b7-44cf-ad81-6d36666157cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['happy', 'not-relevant', 'angry', 'disgust', 'sad', 'surprise'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "labels=df.emotion.unique()\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H4WZn_Y4xUi",
        "outputId": "1f27feaf-d48e-4ff1-d370-b2a0a76a2477"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'happy': 0,\n",
              " 'not-relevant': 1,\n",
              " 'angry': 2,\n",
              " 'disgust': 3,\n",
              " 'sad': 4,\n",
              " 'surprise': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "label_dict = {}\n",
        "for index, possible_label in enumerate(labels):\n",
        "    label_dict[possible_label] = index\n",
        "\n",
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_nlaWecY6jJt",
        "outputId": "dd754be2-285c-4e3e-e287-03328f2391f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      611857364396965889  \\\n",
              "0     614484565059596288   \n",
              "1     614746522043973632   \n",
              "2     614877582664835073   \n",
              "3     611932373039644672   \n",
              "4     611570404268883969   \n",
              "...                  ...   \n",
              "3077  611258135270060033   \n",
              "3078  612214539468279808   \n",
              "3079  613678555935973376   \n",
              "3081  615246897670922240   \n",
              "3082  613016084371914753   \n",
              "\n",
              "     @aandraous @britishmuseum @AndrewsAntonio Merci pour le partage! @openwinemap  \\\n",
              "0     Dorian Gray with Rainbow Scarf #LoveWins (from...                              \n",
              "1     @SelectShowcase @Tate_StIves ... Replace with ...                              \n",
              "2     @Sofabsports thank you for following me back. ...                              \n",
              "3     @britishmuseum @TudorHistory What a beautiful ...                              \n",
              "4     @NationalGallery @ThePoldarkian I have always ...                              \n",
              "...                                                 ...                              \n",
              "3077  @_TheWhitechapel @Campaignforwool @SlowTextile...                              \n",
              "3078  “@britishmuseum: Thanks for ranking us #1 in @...                              \n",
              "3079  MT @AliHaggett: Looking forward to our public ...                              \n",
              "3081           @MrStuchbery @britishmuseum Mesmerising.                              \n",
              "3082  @NationalGallery The 2nd GENOCIDE against #Bia...                              \n",
              "\n",
              "           emotion  label  \n",
              "0            happy      0  \n",
              "1            happy      0  \n",
              "2            happy      0  \n",
              "3            happy      0  \n",
              "4            happy      0  \n",
              "...            ...    ...  \n",
              "3077  not-relevant      1  \n",
              "3078         happy      0  \n",
              "3079         happy      0  \n",
              "3081         happy      0  \n",
              "3082  not-relevant      1  \n",
              "\n",
              "[1481 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da817bbd-e874-4342-ab68-626df84a0be0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>611857364396965889</th>\n",
              "      <th>@aandraous @britishmuseum @AndrewsAntonio Merci pour le partage! @openwinemap</th>\n",
              "      <th>emotion</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>614484565059596288</td>\n",
              "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>614746522043973632</td>\n",
              "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>614877582664835073</td>\n",
              "      <td>@Sofabsports thank you for following me back. ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>611932373039644672</td>\n",
              "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>611570404268883969</td>\n",
              "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3077</th>\n",
              "      <td>611258135270060033</td>\n",
              "      <td>@_TheWhitechapel @Campaignforwool @SlowTextile...</td>\n",
              "      <td>not-relevant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3078</th>\n",
              "      <td>612214539468279808</td>\n",
              "      <td>“@britishmuseum: Thanks for ranking us #1 in @...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3079</th>\n",
              "      <td>613678555935973376</td>\n",
              "      <td>MT @AliHaggett: Looking forward to our public ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3081</th>\n",
              "      <td>615246897670922240</td>\n",
              "      <td>@MrStuchbery @britishmuseum Mesmerising.</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3082</th>\n",
              "      <td>613016084371914753</td>\n",
              "      <td>@NationalGallery The 2nd GENOCIDE against #Bia...</td>\n",
              "      <td>not-relevant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1481 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da817bbd-e874-4342-ab68-626df84a0be0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da817bbd-e874-4342-ab68-626df84a0be0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da817bbd-e874-4342-ab68-626df84a0be0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df['label'] = df[\"emotion\"].replace(label_dict)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "QkFjQICe6sGs",
        "outputId": "3b59de98-b5ee-4c47-b887-e04961845457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb5e9774550>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(df[\"emotion\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LrDs5Zji7ZKK"
      },
      "outputs": [],
      "source": [
        "df.rename(columns={\"@aandraous @britishmuseum @AndrewsAntonio Merci pour le partage! @openwinemap\":\"tweet\"},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "BtMRiBAr7rHx",
        "outputId": "139e635b-2e87-4ecd-ad69-ca6cb64e1ccb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#plot hist of sentence length\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot([len(s) for s in df[\"tweet\"]], bins=100)\n",
        "plt.title('Sentence Length')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmDDjd7u7zsq",
        "outputId": "26695772-d211-420a-e9ff-73abde370971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length:  149\n"
          ]
        }
      ],
      "source": [
        "#find the maximum length\n",
        "max_len = max([len(sent) for sent in df[\"tweet\"]])\n",
        "print('Max length: ', max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "t8jc_8sj76B-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[\"tweet\"], \n",
        "                                                   df[\"label\"],\n",
        "                                                   test_size = 0.15,\n",
        "                                                   random_state = 17,\n",
        "                                                   stratify = df[\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "B2mv7tEw-vFa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "517f03be6bdf4382b7325af067f03095",
            "aeb277b0a468411ebe68467f2ff9a1a1",
            "11cb67bc93a5486680b51372fb96631b",
            "5475d40da5574109bcbce21dc7b9dbcc",
            "694d4be1e3be4e1eb336062b4e676565",
            "3846a642f5b04b4f8c50602e390a3507",
            "a4851168826749dda36cad08346003ed",
            "e04e08b88489446da8c10212427d4259",
            "741d668d5af646d8b9841db4304e3ac9",
            "f9cd3a57db4b49e68efd73b139f34e64",
            "48693750f21a48e2bbbaa9ade64819aa",
            "c217671ff8784a4ca0867a5092da65c4",
            "19be41747ace43d39791995371158713",
            "102ec675ca724201a81435d0fba7a3b1",
            "b686b6d1ca024c21be675fece5266c5c",
            "3bbe7904d219443495dd227308807acc",
            "6c4c17a2a71340e2a0056537b3af3b01",
            "0b9ee6800dfd462bb5c657b5c771abeb",
            "49882b71eb36414ca52085ba38faa974",
            "51b99209b92a465d96ea12c53725a865",
            "de234455d29f4ca69e8c292afd46029d",
            "0abe55b53ccf447993beacf3f62ca3a8",
            "0a61b09279d04bdc8bfcc7e87abe0d4f",
            "cf5cef01a7de419d9e97f7400a0fb610",
            "8d163c6a61e745689d4f4fa7b57b824e",
            "35250e5ffdba410a963ea8612f4f975c",
            "20edcf7373614fb88f6f72118e9a30dd",
            "76772e92545249049b993d4f9641222d",
            "a52760ae46a443cfaa9906bbd89d0cd2",
            "2ebee49612664caebe1d2abe10fe060b",
            "7836127dc99f41f5acb83cc374180443",
            "6434c36dacad465e98acbdacfea6fc3b",
            "5e1c048712824450871003f91c4da64a"
          ]
        },
        "outputId": "fc754201-544d-422e-abfd-375d6f93cd9c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "517f03be6bdf4382b7325af067f03095"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c217671ff8784a4ca0867a5092da65c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a61b09279d04bdc8bfcc7e87abe0d4f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
        "                                         do_lower_case = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zm4LPmpC_cST"
      },
      "outputs": [],
      "source": [
        "train=pd.DataFrame({\"Text\":X_train,\"emotion\":y_train})\n",
        "test= pd.DataFrame({\"Text\":X_test,\"emotion\":y_test})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQKEB8NxMIvA"
      },
      "source": [
        "Just like the other models, we have to convert the words into vectors. For that purpose we are using a bert method to do that task.\n",
        "\n",
        "STEPS:\n",
        "\n",
        "1.Adding special tokens (CLS and SEP). CLS is added in begining and SEP is added at the end.\n",
        "\n",
        "eg: [CLS] Sentence A [SEP] Sentence B [SEP]\n",
        "\n",
        "2.Then we are converting the sentences into a sequence of number\n",
        "\n",
        "3.Also doing the masking operation, the output will be pytorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4faF5RunAtE1"
      },
      "outputs": [],
      "source": [
        "#encode train set\n",
        "#Converting each tweet into a sequence of numbers with the length of 150\n",
        "#Output will be a dictionary of input_ids, token_type_ids and attention_mask\n",
        "#Attention mask contains 0 as masked token and 1 as real token\n",
        "encoded_data_train = tokenizer.batch_encode_plus(train[\"Text\"].values,          \n",
        "                                                add_special_tokes = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 150,\n",
        "                                                return_tensors = 'pt')\n",
        "                                                \n",
        "#encode validation set\n",
        "encoded_data_val = tokenizer.batch_encode_plus(test[\"Text\"].values,\n",
        "                                                add_special_tokes = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 150,\n",
        "                                                return_tensors = 'pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqe_slfmA9e_",
        "outputId": "c79f90a6-066e-4a7b-a0f0-66e96cca216f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1030,  4459,  ...,     0,     0,     0],\n",
              "        [  101,  1030, 12323,  ...,     0,     0,     0],\n",
              "        [  101,  1037,  2261,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  1030,  2329,  ...,     0,     0,     0],\n",
              "        [  101,  1030, 12869,  ...,     0,     0,     0],\n",
              "        [  101,  1012,  1030,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "encoded_data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bIIuKufMKvRo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#train set\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train[\"emotion\"].values)\n",
        "\n",
        "#validation set\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(test[\"emotion\"].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd5Ot9xVLlfL",
        "outputId": "7c865a40-7f86-401b-8a2d-f071b8d687f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "labels_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_DfVm79NqdF"
      },
      "source": [
        "Now we will set up our BERT model through 4 steps:\n",
        "\n",
        "1.Load Pre-trained BERT\n",
        "\n",
        "2.Create DataLoader\n",
        "\n",
        "3.Set up optimizer\n",
        "\n",
        "4.Set up scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "2658a673f7ac4e0e9e428f991e0098dc",
            "351ff803c41544698318511eb4f4793a",
            "b2b7eca3afad49bc88f40eeade756fde",
            "4c9f2554174741ed9c5e60cac749e280",
            "e6ba7d9a354e4ab69e5c088c539225c2",
            "b9ff622d35764c04bb0df0998c3657d1",
            "1638dec07bc749b1873f172bd4997f2f",
            "356ca675e29d43f683f2042f348d8be4",
            "00b49bead3294e15b2d1c46053f54281",
            "860d8497bf854b8c8a2da5bb6784af73",
            "667365311e614240841facd850681195"
          ]
        },
        "id": "nD3vPnESN6ih",
        "outputId": "9dbf4feb-5b0b-4a27-8ef7-1985690b392c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2658a673f7ac4e0e9e428f991e0098dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#1.Loading pre-trained model\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                      num_labels = len(label_dict),\n",
        "                                                      output_attentions = False,\n",
        "                                                      output_hidden_states = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "auyOMg3hO9fb"
      },
      "outputs": [],
      "source": [
        "#2.Create dataloader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "#train set\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "#validation set\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                             attention_masks_val, \n",
        "                             labels_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "h4s6RQihSwKO"
      },
      "outputs": [],
      "source": [
        "#Creating iterator for ourdataset to save memory during training and boost the training speed.\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#train set\n",
        "dataloader_train = DataLoader(dataset_train,\n",
        "                              sampler = RandomSampler(dataset_train),\n",
        "                              batch_size = batch_size)\n",
        "\n",
        "#validation set\n",
        "dataloader_val = DataLoader(dataset_val,\n",
        "                              sampler = RandomSampler(dataset_val),\n",
        "                              batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNbmnvNFUQWW"
      },
      "source": [
        "* Optimizers are used in BERT (and in deep learning in general) to update the model parameters in the direction that minimizes the loss function. \n",
        "\n",
        "* Schedulers are used to adjust the learning rate during training, typically reducing the learning rate over time so that the optimizer can converge more efficiently to the optimal solution. \n",
        "\n",
        "* By using an optimizer and a scheduler, the model can converge faster and achieve better results than if only one or the other is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2as4h8I4TOw_",
        "outputId": "587435c5-087b-460c-b89e-dc36d8332fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#setup optimizer and scheduler\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                 lr = 1e-5,\n",
        "                 eps = 1e-8) \n",
        "                 \n",
        "epochs = 15\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                           num_warmup_steps = 0,\n",
        "                                           num_training_steps = len(dataloader_train)*epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yA6ri1jBUfmU"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "def evaluate(dataloader_val):\n",
        "\n",
        "    #evaluation mode \n",
        "    model.eval()\n",
        "    \n",
        "    #tracking variables\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        #load into GPU\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        #define inputs\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2]}\n",
        "\n",
        "        #compute logits\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "        \n",
        "        #compute loss\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        #compute accuracy\n",
        "        logits = logits.detach().cpu().numpy() #converting tensors to numpy array\n",
        "        label_ids = inputs['labels'].cpu().numpy() #converting tensors to numpy array\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    #compute average loss\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XuQaQflOVuMc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "\n",
        "def f1_score_func(labels,preds):\n",
        "    preds = np.argmax(preds, axis = 1)\n",
        "    return f1_score(labels, preds, average = 'weighted')\n",
        "\n",
        "def accuracy_score_func(labels,preds):\n",
        "    preds = np.argmax(preds, axis = 1)\n",
        "    return accuracy_score(labels, preds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "En9g3ieuw3_J"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKC0EBl9V09y"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "for epoch in range(1, epochs+1):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    accumulation_steps = 10\n",
        "    \n",
        "    loss_train_total = 0\n",
        "    \n",
        "    steps=0\n",
        "    \n",
        "    for input_ids,attention_masks,labels in dataloader_train:\n",
        "        \n",
        "        model.zero_grad() #set gradient to 0\n",
        "        #since we are processing batch by batch, we set gradiant to zero initially.If we does not set to zero, then while computing gradient for 2nd batch\n",
        "        #New gradient=1st batch gradient + 2nd batch gradient, to avoid this, we set gradient to zero\n",
        "    \n",
        "        \n",
        "        #define inputs and loading it into CPU\n",
        "        inputs = {'input_ids':input_ids.to(device),\n",
        "                  'attention_mask':attention_masks.to(device),    #input=In simply,this a single tweet posted by a person\n",
        "                  'labels':labels.to(device)}\n",
        "        \n",
        "        outputs = model(**inputs) #unpack the dict straight into inputs\n",
        "        #output=(loss,logits)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        if (steps + 1) % accumulation_steps == 0:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            model.zero_grad()\n",
        "        else:\n",
        "            loss.backward()\n",
        "        steps += 1\n",
        "        #loss.backward() #computes the gradients of the loss with respect to the model parameters / slope \n",
        "        \n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # This make sure that gradient value does not exceed more than 1\n",
        "        \n",
        "        #optimizer.step() # calculate new_weight=old_weight- learning rate * derivative of loss\n",
        "        #scheduler.step() # It is used to update the learning rate of the optimizer\n",
        "        \n",
        "    torch.save(model.state_dict(), f'Models/ BERT_ft_epoch{epoch}.model')\n",
        "    \n",
        "    taining_loss = loss_train_total / len(dataloader_train)\n",
        "    loss_val_avg, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "\n",
        "    print('Epoch :',epoch)\n",
        "    print('Training loss :', taining_loss)\n",
        "    print('Validation loss :', loss_val_avg)\n",
        "    print('F1 Score (weighted) :',val_f1)\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc = 'Epoch {:1d}'.format(epoch), \n",
        "                        leave = False, \n",
        "                        disable = False)\n",
        "    \n",
        "    #for input_ids,attention_masks,labels in progress_bar:\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        \n",
        "        model.zero_grad() #set gradient to 0\n",
        "        #since we are processing batch by batch, we set gradient to zero else gradient2=gradient1+gradient2(This should not happen)\n",
        "    \n",
        "        #load into GPU\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        #define inputs\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2]}\n",
        "        \n",
        "        outputs = model(**inputs) #unpack the dict straight into inputs\n",
        "        #outputs=(loss,logits)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item() #Example : loss_train_total=tensor(3) if we use loss.item then loss_train_total=3\n",
        "        loss.backward() #calculates slope / gradient with respect to loss\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # It prevent the value of gradient not exeeding 1\n",
        "        \n",
        "        optimizer.step() #updating parameters/ weights\n",
        "        scheduler.step() #Updating learning rate\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
        "\n",
        "\n",
        "        \n",
        "    torch.save(model.state_dict(),'/content/drive/My Drive/Models/BERT_ft_epoch{0}.model'.format(epoch))\n",
        "    \n",
        "    tqdm.write('\\n Epoch {epoch}')   \n",
        "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
        "    tqdm.write('Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(true_vals,predictions)\n",
        "    accuracy=accuracy_score_func(true_vals,predictions)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
        "    tqdm.write(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "_d3If8DLxgyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6f1828-516c-4ac5-bc71-341734a232d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/15 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 0/40 [01:12<?, ?it/s, training_loss=0.600]\u001b[A\n",
            "Epoch 1:   2%|▎         | 1/40 [01:12<47:00, 72.31s/it, training_loss=0.600]\u001b[A\n",
            "Epoch 1:   2%|▎         | 1/40 [02:10<47:00, 72.31s/it, training_loss=0.563]\u001b[A\n",
            "Epoch 1:   5%|▌         | 2/40 [02:10<40:42, 64.28s/it, training_loss=0.563]\u001b[A\n",
            "Epoch 1:   5%|▌         | 2/40 [03:07<40:42, 64.28s/it, training_loss=0.534]\u001b[A\n",
            "Epoch 1:   8%|▊         | 3/40 [03:07<37:34, 60.93s/it, training_loss=0.534]\u001b[A\n",
            "Epoch 1:   8%|▊         | 3/40 [03:58<37:34, 60.93s/it, training_loss=0.518]\u001b[A\n",
            "Epoch 1:  10%|█         | 4/40 [03:58<34:09, 56.94s/it, training_loss=0.518]\u001b[A\n",
            "Epoch 1:  10%|█         | 4/40 [04:49<34:09, 56.94s/it, training_loss=0.491]\u001b[A\n",
            "Epoch 1:  12%|█▎        | 5/40 [04:49<31:59, 54.85s/it, training_loss=0.491]\u001b[A\n",
            "Epoch 1:  12%|█▎        | 5/40 [05:40<31:59, 54.85s/it, training_loss=0.502]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 6/40 [05:40<30:11, 53.28s/it, training_loss=0.502]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 6/40 [06:29<30:11, 53.28s/it, training_loss=0.457]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 7/40 [06:29<28:36, 52.01s/it, training_loss=0.457]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 7/40 [07:18<28:36, 52.01s/it, training_loss=0.523]\u001b[A\n",
            "Epoch 1:  20%|██        | 8/40 [07:18<27:14, 51.07s/it, training_loss=0.523]\u001b[A\n",
            "Epoch 1:  20%|██        | 8/40 [08:07<27:14, 51.07s/it, training_loss=0.408]\u001b[A\n",
            "Epoch 1:  22%|██▎       | 9/40 [08:07<26:05, 50.50s/it, training_loss=0.408]\u001b[A\n",
            "Epoch 1:  22%|██▎       | 9/40 [08:57<26:05, 50.50s/it, training_loss=0.439]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 10/40 [08:57<25:05, 50.18s/it, training_loss=0.439]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 10/40 [09:47<25:05, 50.18s/it, training_loss=0.391]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 11/40 [09:47<24:15, 50.18s/it, training_loss=0.391]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 11/40 [10:37<24:15, 50.18s/it, training_loss=0.415]\u001b[A\n",
            "Epoch 1:  30%|███       | 12/40 [10:37<23:23, 50.12s/it, training_loss=0.415]\u001b[A\n",
            "Epoch 1:  30%|███       | 12/40 [11:27<23:23, 50.12s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:  32%|███▎      | 13/40 [11:27<22:30, 50.01s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:  32%|███▎      | 13/40 [12:18<22:30, 50.01s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 14/40 [12:18<21:47, 50.30s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 14/40 [13:08<21:47, 50.30s/it, training_loss=0.424]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 15/40 [13:08<20:54, 50.17s/it, training_loss=0.424]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 15/40 [13:57<20:54, 50.17s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  40%|████      | 16/40 [13:57<19:58, 49.96s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  40%|████      | 16/40 [14:47<19:58, 49.96s/it, training_loss=0.378]\u001b[A\n",
            "Epoch 1:  42%|████▎     | 17/40 [14:47<19:06, 49.87s/it, training_loss=0.378]\u001b[A\n",
            "Epoch 1:  42%|████▎     | 17/40 [15:37<19:06, 49.87s/it, training_loss=0.387]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 18/40 [15:37<18:19, 49.99s/it, training_loss=0.387]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 18/40 [16:28<18:19, 49.99s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 19/40 [16:28<17:33, 50.17s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 19/40 [17:17<17:33, 50.17s/it, training_loss=0.396]\u001b[A\n",
            "Epoch 1:  50%|█████     | 20/40 [17:17<16:41, 50.05s/it, training_loss=0.396]\u001b[A\n",
            "Epoch 1:  50%|█████     | 20/40 [18:09<16:41, 50.05s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  52%|█████▎    | 21/40 [18:09<16:03, 50.69s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  52%|█████▎    | 21/40 [18:59<16:03, 50.69s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 22/40 [18:59<15:07, 50.40s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 22/40 [19:49<15:07, 50.40s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  57%|█████▊    | 23/40 [19:49<14:11, 50.09s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  57%|█████▊    | 23/40 [20:39<14:11, 50.09s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  60%|██████    | 24/40 [20:40<13:25, 50.34s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  60%|██████    | 24/40 [21:30<13:25, 50.34s/it, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  62%|██████▎   | 25/40 [21:30<12:34, 50.28s/it, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  62%|██████▎   | 25/40 [22:19<12:34, 50.28s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 26/40 [22:19<11:39, 49.97s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 26/40 [23:08<11:39, 49.97s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 27/40 [23:08<10:47, 49.79s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 27/40 [24:01<10:47, 49.79s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  70%|███████   | 28/40 [24:01<10:07, 50.60s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  70%|███████   | 28/40 [24:51<10:07, 50.60s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  72%|███████▎  | 29/40 [24:51<09:14, 50.37s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  72%|███████▎  | 29/40 [25:41<09:14, 50.37s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 30/40 [25:41<08:24, 50.43s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 30/40 [26:32<08:24, 50.43s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 31/40 [26:32<07:35, 50.59s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 31/40 [27:23<07:35, 50.59s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  80%|████████  | 32/40 [27:23<06:46, 50.76s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  80%|████████  | 32/40 [28:14<06:46, 50.76s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  82%|████████▎ | 33/40 [28:14<05:55, 50.78s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  82%|████████▎ | 33/40 [29:05<05:55, 50.78s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 34/40 [29:05<05:05, 50.90s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 34/40 [29:57<05:05, 50.90s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 35/40 [29:57<04:15, 51.14s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 35/40 [30:48<04:15, 51.14s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 36/40 [30:48<03:23, 50.96s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 36/40 [31:38<03:23, 50.96s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  92%|█████████▎| 37/40 [31:38<02:32, 50.81s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  92%|█████████▎| 37/40 [32:28<02:32, 50.81s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 38/40 [32:28<01:41, 50.72s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 38/40 [33:18<01:41, 50.72s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 39/40 [33:18<00:50, 50.43s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 39/40 [33:35<00:50, 50.43s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1: 100%|██████████| 40/40 [33:35<00:00, 40.30s/it, training_loss=0.201]\u001b[A\n",
            "  0%|          | 0/15 [33:37<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:19<01:54, 19.11s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:35<01:27, 17.49s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:51<01:07, 16.92s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [01:08<00:50, 16.70s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [01:24<00:33, 16.57s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [01:40<00:16, 16.51s/it]\u001b[A\n",
            "100%|██████████| 7/7 [01:56<00:00, 16.69s/it]\n",
            "  7%|▋         | 1/15 [35:34<8:18:05, 2134.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.7640282000814166\n",
            "F1 Score (weighted): 0.7218046319099609\n",
            "Accuracy: 0.7937219730941704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 2:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:   0%|          | 0/40 [00:49<?, ?it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 2:   2%|▎         | 1/40 [00:49<32:19, 49.72s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:   2%|▎         | 1/40 [01:40<32:19, 49.72s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:   5%|▌         | 2/40 [01:40<32:01, 50.57s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:   5%|▌         | 2/40 [02:31<32:01, 50.57s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:   8%|▊         | 3/40 [02:31<31:05, 50.42s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:   8%|▊         | 3/40 [03:21<31:05, 50.42s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 2:  10%|█         | 4/40 [03:21<30:19, 50.53s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 2:  10%|█         | 4/40 [04:12<30:19, 50.53s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  12%|█▎        | 5/40 [04:12<29:27, 50.49s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  12%|█▎        | 5/40 [05:02<29:27, 50.49s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 6/40 [05:02<28:30, 50.30s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 6/40 [05:51<28:30, 50.30s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 7/40 [05:51<27:33, 50.11s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 7/40 [06:42<27:33, 50.11s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  20%|██        | 8/40 [06:42<26:52, 50.38s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  20%|██        | 8/40 [07:35<26:52, 50.38s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  22%|██▎       | 9/40 [07:35<26:19, 50.96s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  22%|██▎       | 9/40 [08:26<26:19, 50.96s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 10/40 [08:26<25:33, 51.11s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 10/40 [09:16<25:33, 51.11s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 11/40 [09:16<24:30, 50.70s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 11/40 [10:08<24:30, 50.70s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  30%|███       | 12/40 [10:08<23:55, 51.26s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  30%|███       | 12/40 [10:59<23:55, 51.26s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  32%|███▎      | 13/40 [10:59<22:58, 51.07s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  32%|███▎      | 13/40 [11:50<22:58, 51.07s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 14/40 [11:50<22:05, 51.00s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 14/40 [12:41<22:05, 51.00s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 15/40 [12:41<21:13, 50.94s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 15/40 [13:30<21:13, 50.94s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  40%|████      | 16/40 [13:31<20:15, 50.63s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  40%|████      | 16/40 [14:20<20:15, 50.63s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  42%|████▎     | 17/40 [14:20<19:16, 50.28s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  42%|████▎     | 17/40 [15:10<19:16, 50.28s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 18/40 [15:10<18:25, 50.26s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 18/40 [16:01<18:25, 50.26s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 19/40 [16:01<17:36, 50.32s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 19/40 [16:51<17:36, 50.32s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  50%|█████     | 20/40 [16:51<16:45, 50.27s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  50%|█████     | 20/40 [17:41<16:45, 50.27s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 2:  52%|█████▎    | 21/40 [17:41<15:55, 50.27s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 2:  52%|█████▎    | 21/40 [18:31<15:55, 50.27s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 22/40 [18:31<15:01, 50.06s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 22/40 [19:21<15:01, 50.06s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  57%|█████▊    | 23/40 [19:21<14:10, 50.00s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  57%|█████▊    | 23/40 [20:11<14:10, 50.00s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  60%|██████    | 24/40 [20:11<13:20, 50.04s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  60%|██████    | 24/40 [21:01<13:20, 50.04s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  62%|██████▎   | 25/40 [21:01<12:30, 50.03s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  62%|██████▎   | 25/40 [21:52<12:30, 50.03s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 26/40 [21:52<11:46, 50.45s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 26/40 [22:44<11:46, 50.45s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 27/40 [22:44<11:00, 50.84s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 27/40 [23:35<11:00, 50.84s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  70%|███████   | 28/40 [23:35<10:09, 50.83s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  70%|███████   | 28/40 [24:26<10:09, 50.83s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 2:  72%|███████▎  | 29/40 [24:26<09:21, 51.06s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 2:  72%|███████▎  | 29/40 [25:18<09:21, 51.06s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 30/40 [25:18<08:32, 51.23s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 30/40 [26:09<08:32, 51.23s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 31/40 [26:09<07:41, 51.26s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 31/40 [27:00<07:41, 51.26s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  80%|████████  | 32/40 [27:00<06:49, 51.15s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  80%|████████  | 32/40 [27:50<06:49, 51.15s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  82%|████████▎ | 33/40 [27:50<05:56, 50.92s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  82%|████████▎ | 33/40 [28:41<05:56, 50.92s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 34/40 [28:41<05:04, 50.67s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 34/40 [29:30<05:04, 50.67s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 35/40 [29:30<04:11, 50.37s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 35/40 [30:21<04:11, 50.37s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 36/40 [30:21<03:21, 50.38s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 36/40 [31:11<03:21, 50.38s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  92%|█████████▎| 37/40 [31:11<02:31, 50.41s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  92%|█████████▎| 37/40 [32:01<02:31, 50.41s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 38/40 [32:01<01:40, 50.18s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 38/40 [32:51<01:40, 50.18s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 39/40 [32:51<00:50, 50.17s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 39/40 [33:07<00:50, 50.17s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2: 100%|██████████| 40/40 [33:07<00:00, 40.05s/it, training_loss=0.098]\u001b[A\n",
            "  7%|▋         | 1/15 [1:08:44<8:18:05, 2134.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:17<01:46, 17.76s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:34<01:25, 17.02s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:50<01:06, 16.75s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [01:07<00:49, 16.65s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [01:23<00:33, 16.67s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [01:40<00:16, 16.75s/it]\u001b[A\n",
            "100%|██████████| 7/7 [01:56<00:00, 16.67s/it]\n",
            " 13%|█▎        | 2/15 [1:10:40<7:38:53, 2117.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.6119470468589238\n",
            "F1 Score (weighted): 0.7705324183038922\n",
            "Accuracy: 0.8116591928251121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 3:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:   0%|          | 0/40 [00:52<?, ?it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 3:   2%|▎         | 1/40 [00:52<33:58, 52.28s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:   2%|▎         | 1/40 [01:44<33:58, 52.28s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 3:   5%|▌         | 2/40 [01:44<33:16, 52.53s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 3:   5%|▌         | 2/40 [02:34<33:16, 52.53s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 3:   8%|▊         | 3/40 [02:34<31:35, 51.23s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 3:   8%|▊         | 3/40 [03:24<31:35, 51.23s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 3:  10%|█         | 4/40 [03:24<30:28, 50.80s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 3:  10%|█         | 4/40 [04:15<30:28, 50.80s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  12%|█▎        | 5/40 [04:15<29:31, 50.61s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  12%|█▎        | 5/40 [05:06<29:31, 50.61s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 6/40 [05:06<28:46, 50.77s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 6/40 [05:55<28:46, 50.77s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 7/40 [05:55<27:40, 50.31s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 7/40 [06:44<27:40, 50.31s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  20%|██        | 8/40 [06:44<26:39, 49.99s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  20%|██        | 8/40 [07:34<26:39, 49.99s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 3:  22%|██▎       | 9/40 [07:34<25:47, 49.92s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 3:  22%|██▎       | 9/40 [08:24<25:47, 49.92s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 10/40 [08:24<24:57, 49.93s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 10/40 [09:14<24:57, 49.93s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 11/40 [09:14<24:09, 49.99s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 11/40 [10:07<24:09, 49.99s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  30%|███       | 12/40 [10:07<23:44, 50.87s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  30%|███       | 12/40 [10:58<23:44, 50.87s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 3:  32%|███▎      | 13/40 [10:58<22:57, 51.00s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 3:  32%|███▎      | 13/40 [11:49<22:57, 51.00s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 14/40 [11:49<22:05, 50.97s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 14/40 [12:41<22:05, 50.97s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 15/40 [12:41<21:22, 51.28s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 15/40 [13:32<21:22, 51.28s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 3:  40%|████      | 16/40 [13:32<20:24, 51.01s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 3:  40%|████      | 16/40 [14:22<20:24, 51.01s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  42%|████▎     | 17/40 [14:22<19:27, 50.78s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  42%|████▎     | 17/40 [15:12<19:27, 50.78s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 18/40 [15:12<18:29, 50.44s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 18/40 [16:01<18:29, 50.44s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 19/40 [16:01<17:32, 50.10s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 19/40 [16:51<17:32, 50.10s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  50%|█████     | 20/40 [16:51<16:42, 50.12s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  50%|█████     | 20/40 [17:42<16:42, 50.12s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  52%|█████▎    | 21/40 [17:42<15:55, 50.29s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  52%|█████▎    | 21/40 [18:32<15:55, 50.29s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 22/40 [18:32<15:07, 50.40s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 22/40 [19:23<15:07, 50.40s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  57%|█████▊    | 23/40 [19:23<14:15, 50.34s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  57%|█████▊    | 23/40 [20:12<14:15, 50.34s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  60%|██████    | 24/40 [20:12<13:23, 50.20s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  60%|██████    | 24/40 [21:03<13:23, 50.20s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  62%|██████▎   | 25/40 [21:03<12:33, 50.24s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  62%|██████▎   | 25/40 [21:53<12:33, 50.24s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 26/40 [21:53<11:42, 50.21s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 26/40 [22:43<11:42, 50.21s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 27/40 [22:43<10:51, 50.12s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 27/40 [23:34<10:51, 50.12s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  70%|███████   | 28/40 [23:34<10:06, 50.54s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  70%|███████   | 28/40 [24:24<10:06, 50.54s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  72%|███████▎  | 29/40 [24:24<09:13, 50.28s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  72%|███████▎  | 29/40 [25:14<09:13, 50.28s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 30/40 [25:14<08:21, 50.16s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 30/40 [26:04<08:21, 50.16s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 31/40 [26:04<07:32, 50.23s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 31/40 [26:57<07:32, 50.23s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  80%|████████  | 32/40 [26:57<06:47, 50.90s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  80%|████████  | 32/40 [27:47<06:47, 50.90s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 3:  82%|████████▎ | 33/40 [27:47<05:55, 50.78s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 3:  82%|████████▎ | 33/40 [28:38<05:55, 50.78s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 34/40 [28:38<05:04, 50.68s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 34/40 [29:27<05:04, 50.68s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 35/40 [29:27<04:12, 50.41s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 35/40 [30:17<04:12, 50.41s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 36/40 [30:17<03:21, 50.26s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 36/40 [31:07<03:21, 50.26s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  92%|█████████▎| 37/40 [31:07<02:30, 50.05s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  92%|█████████▎| 37/40 [31:57<02:30, 50.05s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 38/40 [31:57<01:40, 50.19s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 38/40 [32:48<01:40, 50.19s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 39/40 [32:48<00:50, 50.20s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 39/40 [33:04<00:50, 50.20s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 3: 100%|██████████| 40/40 [33:04<00:00, 40.03s/it, training_loss=0.260]\u001b[A\n",
            " 13%|█▎        | 2/15 [1:43:47<7:38:53, 2117.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:17<01:45, 17.54s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:33<01:23, 16.77s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:50<01:06, 16.59s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [01:06<00:49, 16.50s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [01:22<00:32, 16.46s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [01:39<00:16, 16.40s/it]\u001b[A\n",
            "100%|██████████| 7/7 [01:55<00:00, 16.43s/it]\n",
            " 20%|██        | 3/15 [1:45:42<7:02:04, 2110.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.5986088003431048\n",
            "F1 Score (weighted): 0.7810979752683789\n",
            "Accuracy: 0.820627802690583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 4:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:   0%|          | 0/40 [00:49<?, ?it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 4:   2%|▎         | 1/40 [00:49<32:07, 49.41s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 4:   2%|▎         | 1/40 [01:39<32:07, 49.41s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 4:   5%|▌         | 2/40 [01:39<31:31, 49.77s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 4:   5%|▌         | 2/40 [02:29<31:31, 49.77s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 4:   8%|▊         | 3/40 [02:29<30:43, 49.83s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 4:   8%|▊         | 3/40 [03:20<30:43, 49.83s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 4:  10%|█         | 4/40 [03:20<30:06, 50.18s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 4:  10%|█         | 4/40 [04:10<30:06, 50.18s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 4:  12%|█▎        | 5/40 [04:10<29:16, 50.19s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 4:  12%|█▎        | 5/40 [05:00<29:16, 50.19s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 4:  15%|█▌        | 6/40 [05:00<28:24, 50.12s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 4:  15%|█▌        | 6/40 [05:49<28:24, 50.12s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 7/40 [05:49<27:27, 49.92s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 7/40 [06:39<27:27, 49.92s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 4:  20%|██        | 8/40 [06:39<26:32, 49.76s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 4:  20%|██        | 8/40 [07:28<26:32, 49.76s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 4:  22%|██▎       | 9/40 [07:28<25:41, 49.73s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 4:  22%|██▎       | 9/40 [08:19<25:41, 49.73s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 4:  25%|██▌       | 10/40 [08:19<25:02, 50.08s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 4:  25%|██▌       | 10/40 [09:10<25:02, 50.08s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 11/40 [09:10<24:20, 50.38s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 11/40 [10:01<24:20, 50.38s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 4:  30%|███       | 12/40 [10:01<23:32, 50.43s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 4:  30%|███       | 12/40 [10:51<23:32, 50.43s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 4:  32%|███▎      | 13/40 [10:51<22:41, 50.41s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 4:  32%|███▎      | 13/40 [11:41<22:41, 50.41s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 4:  35%|███▌      | 14/40 [11:41<21:49, 50.38s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 4:  35%|███▌      | 14/40 [12:32<21:49, 50.38s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 15/40 [12:32<20:58, 50.36s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 15/40 [13:22<20:58, 50.36s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 4:  40%|████      | 16/40 [13:22<20:06, 50.26s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 4:  40%|████      | 16/40 [14:14<20:06, 50.26s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 4:  42%|████▎     | 17/40 [14:14<19:29, 50.85s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 4:  42%|████▎     | 17/40 [15:04<19:29, 50.85s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 4:  45%|████▌     | 18/40 [15:04<18:32, 50.58s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 4:  45%|████▌     | 18/40 [15:54<18:32, 50.58s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 19/40 [15:54<17:38, 50.41s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 19/40 [16:44<17:38, 50.41s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 4:  50%|█████     | 20/40 [16:44<16:48, 50.44s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 4:  50%|█████     | 20/40 [17:36<16:48, 50.44s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 4:  52%|█████▎    | 21/40 [17:36<16:03, 50.72s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 4:  52%|█████▎    | 21/40 [18:27<16:03, 50.72s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 4:  55%|█████▌    | 22/40 [18:27<15:17, 50.94s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 4:  55%|█████▌    | 22/40 [19:18<15:17, 50.94s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 4:  57%|█████▊    | 23/40 [19:18<14:23, 50.77s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 4:  57%|█████▊    | 23/40 [20:08<14:23, 50.77s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 4:  60%|██████    | 24/40 [20:08<13:30, 50.67s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 4:  60%|██████    | 24/40 [20:59<13:30, 50.67s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 4:  62%|██████▎   | 25/40 [20:59<12:40, 50.72s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 4:  62%|██████▎   | 25/40 [21:50<12:40, 50.72s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 4:  65%|██████▌   | 26/40 [21:50<11:52, 50.89s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 4:  65%|██████▌   | 26/40 [22:42<11:52, 50.89s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 27/40 [22:42<11:03, 51.06s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 27/40 [23:32<11:03, 51.06s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 4:  70%|███████   | 28/40 [23:32<10:09, 50.80s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 4:  70%|███████   | 28/40 [24:22<10:09, 50.80s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 4:  72%|███████▎  | 29/40 [24:22<09:17, 50.70s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 4:  72%|███████▎  | 29/40 [25:13<09:17, 50.70s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 4:  75%|███████▌  | 30/40 [25:13<08:25, 50.57s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 4:  75%|███████▌  | 30/40 [26:03<08:25, 50.57s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 31/40 [26:03<07:35, 50.61s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 31/40 [26:55<07:35, 50.61s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 4:  80%|████████  | 32/40 [26:55<06:47, 50.93s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 4:  80%|████████  | 32/40 [27:46<06:47, 50.93s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 4:  82%|████████▎ | 33/40 [27:46<05:55, 50.80s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 4:  82%|████████▎ | 33/40 [28:36<05:55, 50.80s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 4:  85%|████████▌ | 34/40 [28:36<05:04, 50.74s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 4:  85%|████████▌ | 34/40 [29:27<05:04, 50.74s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 35/40 [29:27<04:13, 50.77s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 35/40 [30:18<04:13, 50.77s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 4:  90%|█████████ | 36/40 [30:18<03:23, 50.77s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 4:  90%|█████████ | 36/40 [31:10<03:23, 50.77s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 4:  92%|█████████▎| 37/40 [31:10<02:33, 51.08s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 4:  92%|█████████▎| 37/40 [31:59<02:33, 51.08s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 38/40 [31:59<01:41, 50.63s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 38/40 [32:49<01:41, 50.63s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 39/40 [32:49<00:50, 50.35s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 39/40 [33:05<00:50, 50.35s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 4: 100%|██████████| 40/40 [33:05<00:00, 40.19s/it, training_loss=0.187]\u001b[A\n",
            " 20%|██        | 3/15 [2:18:49<7:02:04, 2110.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:17<01:45, 17.56s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:34<01:25, 17.12s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:51<01:09, 17.29s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [01:09<00:51, 17.31s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [01:26<00:34, 17.33s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [01:43<00:17, 17.28s/it]\u001b[A\n",
            "100%|██████████| 7/7 [02:00<00:00, 17.19s/it]\n",
            " 27%|██▋       | 4/15 [2:20:50<6:26:43, 2109.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.5883300474711827\n",
            "F1 Score (weighted): 0.7913155090931329\n",
            "Accuracy: 0.8295964125560538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 5:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:   0%|          | 0/40 [00:53<?, ?it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 5:   2%|▎         | 1/40 [00:53<34:46, 53.51s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 5:   2%|▎         | 1/40 [01:44<34:46, 53.51s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 5:   5%|▌         | 2/40 [01:44<33:05, 52.25s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 5:   5%|▌         | 2/40 [02:41<33:05, 52.25s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 5:   8%|▊         | 3/40 [02:41<33:28, 54.28s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 5:   8%|▊         | 3/40 [03:32<33:28, 54.28s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 5:  10%|█         | 4/40 [03:32<31:50, 53.08s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 5:  10%|█         | 4/40 [04:24<31:50, 53.08s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 5:  12%|█▎        | 5/40 [04:24<30:34, 52.42s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 5:  12%|█▎        | 5/40 [05:15<30:34, 52.42s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 5:  15%|█▌        | 6/40 [05:15<29:32, 52.12s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 5:  15%|█▌        | 6/40 [06:08<29:32, 52.12s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 7/40 [06:08<28:48, 52.37s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 7/40 [07:00<28:48, 52.37s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 5:  20%|██        | 8/40 [07:00<27:50, 52.21s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 5:  20%|██        | 8/40 [07:51<27:50, 52.21s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 5:  22%|██▎       | 9/40 [07:51<26:43, 51.74s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 5:  22%|██▎       | 9/40 [08:41<26:43, 51.74s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 5:  25%|██▌       | 10/40 [08:41<25:43, 51.46s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 5:  25%|██▌       | 10/40 [09:34<25:43, 51.46s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 11/40 [09:34<24:58, 51.67s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 11/40 [10:26<24:58, 51.67s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 5:  30%|███       | 12/40 [10:26<24:15, 51.98s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 5:  30%|███       | 12/40 [11:18<24:15, 51.98s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 5:  32%|███▎      | 13/40 [11:18<23:21, 51.91s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 5:  32%|███▎      | 13/40 [12:09<23:21, 51.91s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 5:  35%|███▌      | 14/40 [12:09<22:22, 51.65s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 5:  35%|███▌      | 14/40 [13:00<22:22, 51.65s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 15/40 [13:00<21:25, 51.43s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 15/40 [13:51<21:25, 51.43s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 5:  40%|████      | 16/40 [13:51<20:28, 51.21s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 5:  40%|████      | 16/40 [14:40<20:28, 51.21s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 5:  42%|████▎     | 17/40 [14:40<19:28, 50.80s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 5:  42%|████▎     | 17/40 [15:30<19:28, 50.80s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 5:  45%|████▌     | 18/40 [15:30<18:31, 50.54s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 5:  45%|████▌     | 18/40 [16:20<18:31, 50.54s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 19/40 [16:20<17:37, 50.38s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 19/40 [17:10<17:37, 50.38s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 5:  50%|█████     | 20/40 [17:10<16:44, 50.21s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 5:  50%|█████     | 20/40 [18:01<16:44, 50.21s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 5:  52%|█████▎    | 21/40 [18:01<15:55, 50.28s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 5:  52%|█████▎    | 21/40 [18:53<15:55, 50.28s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 5:  55%|█████▌    | 22/40 [18:53<15:14, 50.81s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 5:  55%|█████▌    | 22/40 [19:44<15:14, 50.81s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 5:  57%|█████▊    | 23/40 [19:44<14:24, 50.86s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 5:  57%|█████▊    | 23/40 [20:34<14:24, 50.86s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 5:  60%|██████    | 24/40 [20:34<13:31, 50.72s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 5:  60%|██████    | 24/40 [21:30<13:31, 50.72s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 5:  62%|██████▎   | 25/40 [21:30<13:01, 52.13s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 5:  62%|██████▎   | 25/40 [22:20<13:01, 52.13s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 5:  65%|██████▌   | 26/40 [22:20<12:04, 51.78s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 5:  65%|██████▌   | 26/40 [23:10<12:04, 51.78s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 27/40 [23:10<11:05, 51.16s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 27/40 [24:00<11:05, 51.16s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 5:  70%|███████   | 28/40 [24:00<10:09, 50.76s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 5:  70%|███████   | 28/40 [24:50<10:09, 50.76s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 5:  72%|███████▎  | 29/40 [24:50<09:15, 50.49s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 5:  72%|███████▎  | 29/40 [25:39<09:15, 50.49s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 5:  75%|███████▌  | 30/40 [25:39<08:22, 50.20s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 5:  75%|███████▌  | 30/40 [26:31<08:22, 50.20s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 31/40 [26:31<07:35, 50.58s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 31/40 [27:21<07:35, 50.58s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 5:  80%|████████  | 32/40 [27:21<06:43, 50.40s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 5:  80%|████████  | 32/40 [28:11<06:43, 50.40s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 5:  82%|████████▎ | 33/40 [28:11<05:51, 50.23s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 5:  82%|████████▎ | 33/40 [29:01<05:51, 50.23s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 5:  85%|████████▌ | 34/40 [29:01<05:01, 50.25s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 5:  85%|████████▌ | 34/40 [29:51<05:01, 50.25s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 35/40 [29:51<04:10, 50.11s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 35/40 [30:41<04:10, 50.11s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 5:  90%|█████████ | 36/40 [30:41<03:20, 50.23s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 5:  90%|█████████ | 36/40 [31:32<03:20, 50.23s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 5:  92%|█████████▎| 37/40 [31:32<02:31, 50.46s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 5:  92%|█████████▎| 37/40 [32:22<02:31, 50.46s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 38/40 [32:22<01:40, 50.28s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 38/40 [33:12<01:40, 50.28s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 39/40 [33:12<00:50, 50.26s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 39/40 [33:29<00:50, 50.26s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 5: 100%|██████████| 40/40 [33:29<00:00, 40.10s/it, training_loss=0.111]\u001b[A\n",
            " 27%|██▋       | 4/15 [2:54:21<6:26:43, 2109.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:18<01:48, 18.13s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:34<01:26, 17.26s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:51<01:07, 16.83s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [01:07<00:50, 16.68s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [01:24<00:33, 16.87s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [01:42<00:17, 17.06s/it]\u001b[A\n",
            "100%|██████████| 7/7 [01:58<00:00, 16.98s/it]\n",
            " 33%|███▎      | 5/15 [2:56:20<5:52:48, 2116.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.5834192676203591\n",
            "F1 Score (weighted): 0.7963046400076895\n",
            "Accuracy: 0.8340807174887892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 6:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:   0%|          | 0/40 [00:51<?, ?it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 6:   2%|▎         | 1/40 [00:51<33:30, 51.54s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 6:   2%|▎         | 1/40 [01:42<33:30, 51.54s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 6:   5%|▌         | 2/40 [01:42<32:17, 50.99s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 6:   5%|▌         | 2/40 [02:32<32:17, 50.99s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 6:   8%|▊         | 3/40 [02:32<31:08, 50.49s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 6:   8%|▊         | 3/40 [03:22<31:08, 50.49s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 6:  10%|█         | 4/40 [03:22<30:11, 50.31s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 6:  10%|█         | 4/40 [04:12<30:11, 50.31s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 6:  12%|█▎        | 5/40 [04:12<29:19, 50.27s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 6:  12%|█▎        | 5/40 [05:03<29:19, 50.27s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 6:  15%|█▌        | 6/40 [05:03<28:40, 50.59s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 6:  15%|█▌        | 6/40 [05:53<28:40, 50.59s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 6:  18%|█▊        | 7/40 [05:53<27:42, 50.39s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 6:  18%|█▊        | 7/40 [06:45<27:42, 50.39s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 6:  20%|██        | 8/40 [06:45<27:14, 51.07s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 6:  20%|██        | 8/40 [07:35<27:14, 51.07s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 6:  22%|██▎       | 9/40 [07:35<26:12, 50.71s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 6:  22%|██▎       | 9/40 [08:26<26:12, 50.71s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 6:  25%|██▌       | 10/40 [08:26<25:22, 50.76s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 6:  25%|██▌       | 10/40 [09:17<25:22, 50.76s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 6:  28%|██▊       | 11/40 [09:17<24:30, 50.71s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 6:  28%|██▊       | 11/40 [10:07<24:30, 50.71s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 6:  30%|███       | 12/40 [10:07<23:35, 50.56s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 6:  30%|███       | 12/40 [10:56<23:35, 50.56s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 6:  32%|███▎      | 13/40 [10:57<22:35, 50.21s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 6:  32%|███▎      | 13/40 [11:46<22:35, 50.21s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 6:  35%|███▌      | 14/40 [11:46<21:41, 50.04s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 6:  35%|███▌      | 14/40 [12:36<21:41, 50.04s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 6:  38%|███▊      | 15/40 [12:36<20:49, 49.97s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 6:  38%|███▊      | 15/40 [13:27<20:49, 49.97s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 6:  40%|████      | 16/40 [13:27<20:07, 50.33s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 6:  40%|████      | 16/40 [14:18<20:07, 50.33s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 6:  42%|████▎     | 17/40 [14:18<19:22, 50.55s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 6:  42%|████▎     | 17/40 [15:08<19:22, 50.55s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 6:  45%|████▌     | 18/40 [15:08<18:28, 50.38s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 6:  45%|████▌     | 18/40 [15:58<18:28, 50.38s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 6:  48%|████▊     | 19/40 [15:58<17:35, 50.27s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 6:  48%|████▊     | 19/40 [16:48<17:35, 50.27s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 6:  50%|█████     | 20/40 [16:48<16:42, 50.15s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 6:  50%|█████     | 20/40 [17:38<16:42, 50.15s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 6:  52%|█████▎    | 21/40 [17:38<15:52, 50.13s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 6:  52%|█████▎    | 21/40 [18:30<15:52, 50.13s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 6:  55%|█████▌    | 22/40 [18:30<15:09, 50.51s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 6:  55%|█████▌    | 22/40 [19:20<15:09, 50.51s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 6:  57%|█████▊    | 23/40 [19:20<14:20, 50.60s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 6:  57%|█████▊    | 23/40 [20:11<14:20, 50.60s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 6:  60%|██████    | 24/40 [20:11<13:30, 50.66s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 6:  60%|██████    | 24/40 [21:01<13:30, 50.66s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 6:  62%|██████▎   | 25/40 [21:01<12:37, 50.50s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 6:  62%|██████▎   | 25/40 [21:52<12:37, 50.50s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 6:  65%|██████▌   | 26/40 [21:52<11:49, 50.69s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 6:  65%|██████▌   | 26/40 [22:45<11:49, 50.69s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 6:  68%|██████▊   | 27/40 [22:45<11:05, 51.20s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 6:  68%|██████▊   | 27/40 [23:35<11:05, 51.20s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 6:  70%|███████   | 28/40 [23:35<10:12, 51.04s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 6:  70%|███████   | 28/40 [24:26<10:12, 51.04s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 6:  72%|███████▎  | 29/40 [24:26<09:20, 50.92s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 6:  72%|███████▎  | 29/40 [25:17<09:20, 50.92s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 6:  75%|███████▌  | 30/40 [25:17<08:27, 50.80s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 6:  75%|███████▌  | 30/40 [26:08<08:27, 50.80s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 6:  78%|███████▊  | 31/40 [26:08<07:38, 50.90s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 6:  78%|███████▊  | 31/40 [27:01<07:38, 50.90s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 6:  80%|████████  | 32/40 [27:01<06:51, 51.48s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 6:  80%|████████  | 32/40 [27:53<06:51, 51.48s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 6:  82%|████████▎ | 33/40 [27:53<06:01, 51.68s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 6:  82%|████████▎ | 33/40 [28:44<06:01, 51.68s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 6:  85%|████████▌ | 34/40 [28:44<05:08, 51.46s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 6:  85%|████████▌ | 34/40 [29:34<05:08, 51.46s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 6:  88%|████████▊ | 35/40 [29:34<04:16, 51.25s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 6:  88%|████████▊ | 35/40 [30:25<04:16, 51.25s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 6:  90%|█████████ | 36/40 [30:25<03:24, 51.01s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 6:  90%|█████████ | 36/40 [31:17<03:24, 51.01s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 6:  92%|█████████▎| 37/40 [31:17<02:33, 51.30s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 6:  92%|█████████▎| 37/40 [32:08<02:33, 51.30s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 6:  95%|█████████▌| 38/40 [32:08<01:42, 51.34s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 6:  95%|█████████▌| 38/40 [32:59<01:42, 51.34s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 6:  98%|█████████▊| 39/40 [32:59<00:51, 51.18s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 6:  98%|█████████▊| 39/40 [33:16<00:51, 51.18s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 6: 100%|██████████| 40/40 [33:16<00:00, 40.84s/it, training_loss=0.106]\u001b[A\n",
            " 33%|███▎      | 5/15 [3:29:38<5:52:48, 2116.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:17<01:46, 17.71s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:34<01:25, 17.02s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:51<01:07, 16.91s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [01:08<00:50, 16.95s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [01:25<00:33, 16.97s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [01:42<00:17, 17.03s/it]\u001b[A\n",
            "100%|██████████| 7/7 [01:58<00:00, 16.93s/it]\n",
            " 40%|████      | 6/15 [3:31:36<5:17:30, 2116.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.5862204028027398\n",
            "F1 Score (weighted): 0.7950694050121404\n",
            "Accuracy: 0.8295964125560538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 7:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:   0%|          | 0/40 [00:51<?, ?it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 7:   2%|▎         | 1/40 [00:51<33:15, 51.15s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 7:   2%|▎         | 1/40 [01:41<33:15, 51.15s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 7:   5%|▌         | 2/40 [01:41<32:06, 50.69s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 7:   5%|▌         | 2/40 [02:34<32:06, 50.69s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 7:   8%|▊         | 3/40 [02:34<31:49, 51.62s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 7:   8%|▊         | 3/40 [03:25<31:49, 51.62s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 7:  10%|█         | 4/40 [03:25<30:49, 51.38s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 7:  10%|█         | 4/40 [04:16<30:49, 51.38s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 7:  12%|█▎        | 5/40 [04:16<29:51, 51.17s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 7:  12%|█▎        | 5/40 [05:06<29:51, 51.17s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 7:  15%|█▌        | 6/40 [05:06<28:45, 50.76s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 7:  15%|█▌        | 6/40 [05:56<28:45, 50.76s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 7:  18%|█▊        | 7/40 [05:56<27:48, 50.57s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 7:  18%|█▊        | 7/40 [06:46<27:48, 50.57s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 7:  20%|██        | 8/40 [06:46<26:52, 50.40s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 7:  20%|██        | 8/40 [07:37<26:52, 50.40s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 7:  22%|██▎       | 9/40 [07:37<26:06, 50.54s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 7:  22%|██▎       | 9/40 [08:28<26:06, 50.54s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 7:  25%|██▌       | 10/40 [08:28<25:21, 50.71s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 7:  25%|██▌       | 10/40 [09:17<25:21, 50.71s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 7:  28%|██▊       | 11/40 [09:17<24:21, 50.41s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 7:  28%|██▊       | 11/40 [10:09<24:21, 50.41s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 7:  30%|███       | 12/40 [10:09<23:38, 50.65s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 7:  30%|███       | 12/40 [11:00<23:38, 50.65s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 7:  32%|███▎      | 13/40 [11:00<22:57, 51.01s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 7:  32%|███▎      | 13/40 [11:52<22:57, 51.01s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 7:  35%|███▌      | 14/40 [11:52<22:07, 51.05s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 7:  35%|███▌      | 14/40 [12:44<22:07, 51.05s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 7:  38%|███▊      | 15/40 [12:44<21:28, 51.53s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 7:  38%|███▊      | 15/40 [13:34<21:28, 51.53s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 7:  40%|████      | 16/40 [13:34<20:26, 51.10s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 7:  40%|████      | 16/40 [14:24<20:26, 51.10s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 7:  42%|████▎     | 17/40 [14:24<19:28, 50.82s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 7:  42%|████▎     | 17/40 [15:14<19:28, 50.82s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 7:  45%|████▌     | 18/40 [15:14<18:32, 50.55s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 7:  45%|████▌     | 18/40 [16:04<18:32, 50.55s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 7:  48%|████▊     | 19/40 [16:04<17:36, 50.31s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 7:  48%|████▊     | 19/40 [16:56<17:36, 50.31s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 7:  50%|█████     | 20/40 [16:56<16:57, 50.88s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 7:  50%|█████     | 20/40 [17:46<16:57, 50.88s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 7:  52%|█████▎    | 21/40 [17:46<16:01, 50.61s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 7:  52%|█████▎    | 21/40 [18:36<16:01, 50.61s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 7:  55%|█████▌    | 22/40 [18:36<15:06, 50.36s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 7:  55%|█████▌    | 22/40 [19:26<15:06, 50.36s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 7:  57%|█████▊    | 23/40 [19:26<14:12, 50.14s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 7:  57%|█████▊    | 23/40 [20:15<14:12, 50.14s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 7:  60%|██████    | 24/40 [20:15<13:19, 49.99s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 7:  60%|██████    | 24/40 [21:05<13:19, 49.99s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 7:  62%|██████▎   | 25/40 [21:05<12:30, 50.01s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 7:  62%|██████▎   | 25/40 [21:56<12:30, 50.01s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 7:  65%|██████▌   | 26/40 [21:56<11:43, 50.24s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 7:  65%|██████▌   | 26/40 [22:46<11:43, 50.24s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 7:  68%|██████▊   | 27/40 [22:46<10:51, 50.09s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 7:  68%|██████▊   | 27/40 [23:35<10:51, 50.09s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 7:  70%|███████   | 28/40 [23:35<09:58, 49.91s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 7:  70%|███████   | 28/40 [24:25<09:58, 49.91s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 7:  72%|███████▎  | 29/40 [24:25<09:07, 49.77s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 7:  72%|███████▎  | 29/40 [25:14<09:07, 49.77s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 7:  75%|███████▌  | 30/40 [25:14<08:16, 49.61s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 7:  75%|███████▌  | 30/40 [26:04<08:16, 49.61s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 7:  78%|███████▊  | 31/40 [26:04<07:26, 49.60s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 7:  78%|███████▊  | 31/40 [26:56<07:26, 49.60s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 7:  80%|████████  | 32/40 [26:56<06:43, 50.41s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 7:  80%|████████  | 32/40 [27:46<06:43, 50.41s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 7:  82%|████████▎ | 33/40 [27:46<05:52, 50.32s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 7:  82%|████████▎ | 33/40 [28:36<05:52, 50.32s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 7:  85%|████████▌ | 34/40 [28:36<05:00, 50.10s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 7:  85%|████████▌ | 34/40 [29:25<05:00, 50.10s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 7:  88%|████████▊ | 35/40 [29:25<04:09, 49.86s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 7:  88%|████████▊ | 35/40 [30:15<04:09, 49.86s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 7:  90%|█████████ | 36/40 [30:15<03:19, 49.81s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 7:  90%|█████████ | 36/40 [31:04<03:19, 49.81s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 7:  92%|█████████▎| 37/40 [31:04<02:28, 49.65s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 7:  92%|█████████▎| 37/40 [31:54<02:28, 49.65s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 7:  95%|█████████▌| 38/40 [31:54<01:39, 49.77s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 7:  95%|█████████▌| 38/40 [32:45<01:39, 49.77s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 7:  98%|█████████▊| 39/40 [32:45<00:49, 49.98s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 7:  98%|█████████▊| 39/40 [33:01<00:49, 49.98s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 7: 100%|██████████| 40/40 [33:01<00:00, 39.86s/it, training_loss=0.055]\u001b[A\n",
            " 40%|████      | 6/15 [4:04:39<5:17:30, 2116.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:17<01:44, 17.42s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:33<01:24, 16.81s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:50<01:06, 16.59s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [01:06<00:49, 16.44s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [01:22<00:32, 16.38s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [01:38<00:16, 16.37s/it]\u001b[A\n",
            "100%|██████████| 7/7 [01:54<00:00, 16.40s/it]\n",
            " 47%|████▋     | 7/15 [4:06:34<4:41:24, 2110.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.5709201736109597\n",
            "F1 Score (weighted): 0.7925583534552145\n",
            "Accuracy: 0.8251121076233184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 8:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:   0%|          | 0/40 [00:53<?, ?it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 8:   2%|▎         | 1/40 [00:53<34:44, 53.44s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 8:   2%|▎         | 1/40 [01:45<34:44, 53.44s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 8:   5%|▌         | 2/40 [01:45<33:22, 52.70s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 8:   5%|▌         | 2/40 [02:35<33:22, 52.70s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 8:   8%|▊         | 3/40 [02:35<31:39, 51.34s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 8:   8%|▊         | 3/40 [03:24<31:39, 51.34s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 8:  10%|█         | 4/40 [03:24<30:19, 50.55s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 8:  10%|█         | 4/40 [04:13<30:19, 50.55s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 8:  12%|█▎        | 5/40 [04:13<29:13, 50.10s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 8:  12%|█▎        | 5/40 [05:03<29:13, 50.10s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 8:  15%|█▌        | 6/40 [05:03<28:18, 49.95s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 8:  15%|█▌        | 6/40 [05:52<28:18, 49.95s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 8:  18%|█▊        | 7/40 [05:52<27:21, 49.75s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 8:  18%|█▊        | 7/40 [06:43<27:21, 49.75s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 8:  20%|██        | 8/40 [06:43<26:36, 49.89s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 8:  20%|██        | 8/40 [07:35<26:36, 49.89s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 8:  22%|██▎       | 9/40 [07:35<26:06, 50.54s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 8:  22%|██▎       | 9/40 [08:24<26:06, 50.54s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 8:  25%|██▌       | 10/40 [08:24<25:09, 50.32s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 8:  25%|██▌       | 10/40 [09:14<25:09, 50.32s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 8:  28%|██▊       | 11/40 [09:14<24:13, 50.13s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 8:  28%|██▊       | 11/40 [10:03<24:13, 50.13s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 8:  30%|███       | 12/40 [10:03<23:16, 49.88s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 8:  30%|███       | 12/40 [10:53<23:16, 49.88s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 8:  32%|███▎      | 13/40 [10:53<22:22, 49.71s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 8:  32%|███▎      | 13/40 [11:42<22:22, 49.71s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 8:  35%|███▌      | 14/40 [11:42<21:28, 49.55s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 8:  35%|███▌      | 14/40 [12:32<21:28, 49.55s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 8:  38%|███▊      | 15/40 [12:32<20:40, 49.64s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 8:  38%|███▊      | 15/40 [13:21<20:40, 49.64s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 8:  40%|████      | 16/40 [13:21<19:50, 49.62s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 8:  40%|████      | 16/40 [14:10<19:50, 49.62s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 8:  42%|████▎     | 17/40 [14:10<18:56, 49.42s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 8:  42%|████▎     | 17/40 [14:59<18:56, 49.42s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 8:  45%|████▌     | 18/40 [14:59<18:04, 49.29s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 8:  45%|████▌     | 18/40 [15:48<18:04, 49.29s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 8:  48%|████▊     | 19/40 [15:48<17:12, 49.16s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 8:  48%|████▊     | 19/40 [16:37<17:12, 49.16s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 8:  50%|█████     | 20/40 [16:37<16:22, 49.12s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 8:  50%|█████     | 20/40 [17:26<16:22, 49.12s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 8:  52%|█████▎    | 21/40 [17:26<15:32, 49.10s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 8:  52%|█████▎    | 21/40 [18:16<15:32, 49.10s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 8:  55%|█████▌    | 22/40 [18:16<14:45, 49.20s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 8:  55%|█████▌    | 22/40 [19:05<14:45, 49.20s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 8:  57%|█████▊    | 23/40 [19:05<13:58, 49.30s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 8:  57%|█████▊    | 23/40 [19:55<13:58, 49.30s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 8:  60%|██████    | 24/40 [19:55<13:11, 49.45s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 8:  60%|██████    | 24/40 [20:44<13:11, 49.45s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 8:  62%|██████▎   | 25/40 [20:44<12:20, 49.39s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 8:  62%|██████▎   | 25/40 [21:33<12:20, 49.39s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 8:  65%|██████▌   | 26/40 [21:33<11:30, 49.32s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 8:  65%|██████▌   | 26/40 [22:23<11:30, 49.32s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 8:  68%|██████▊   | 27/40 [22:23<10:41, 49.32s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 8:  68%|██████▊   | 27/40 [23:12<10:41, 49.32s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 8:  70%|███████   | 28/40 [23:12<09:50, 49.23s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 8:  70%|███████   | 28/40 [24:01<09:50, 49.23s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 8:  72%|███████▎  | 29/40 [24:01<09:01, 49.20s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 8:  72%|███████▎  | 29/40 [24:50<09:01, 49.20s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 8:  75%|███████▌  | 30/40 [24:50<08:11, 49.16s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 8:  75%|███████▌  | 30/40 [25:40<08:11, 49.16s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 8:  78%|███████▊  | 31/40 [25:40<07:24, 49.39s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 8:  78%|███████▊  | 31/40 [26:30<07:24, 49.39s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 8:  80%|████████  | 32/40 [26:30<06:35, 49.50s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 8:  80%|████████  | 32/40 [27:19<06:35, 49.50s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 8:  82%|████████▎ | 33/40 [27:19<05:46, 49.45s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 8:  82%|████████▎ | 33/40 [28:08<05:46, 49.45s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 8:  85%|████████▌ | 34/40 [28:08<04:56, 49.36s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 8:  85%|████████▌ | 34/40 [28:57<04:56, 49.36s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 8:  88%|████████▊ | 35/40 [28:57<04:06, 49.26s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 8:  88%|████████▊ | 35/40 [29:46<04:06, 49.26s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 8:  90%|█████████ | 36/40 [29:46<03:16, 49.17s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 8:  90%|█████████ | 36/40 [30:35<03:16, 49.17s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 8:  92%|█████████▎| 37/40 [30:35<02:27, 49.22s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 8:  92%|█████████▎| 37/40 [31:25<02:27, 49.22s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 8:  95%|█████████▌| 38/40 [31:25<01:38, 49.21s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 8:  95%|█████████▌| 38/40 [32:14<01:38, 49.21s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 8:  98%|█████████▊| 39/40 [32:14<00:49, 49.33s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 8:  98%|█████████▊| 39/40 [32:30<00:49, 49.33s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 8: 100%|██████████| 40/40 [32:30<00:00, 39.31s/it, training_loss=0.061]\u001b[A\n",
            " 47%|████▋     | 7/15 [4:39:07<4:41:24, 2110.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:17<01:47, 17.87s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:34<01:24, 16.92s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:50<01:06, 16.69s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [01:06<00:49, 16.57s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [01:23<00:32, 16.43s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [01:39<00:16, 16.41s/it]\u001b[A\n",
            "100%|██████████| 7/7 [01:55<00:00, 16.48s/it]\n",
            " 53%|█████▎    | 8/15 [4:41:03<4:04:39, 2097.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.5875080951622554\n",
            "F1 Score (weighted): 0.7891540510468998\n",
            "Accuracy: 0.820627802690583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 9:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:   0%|          | 0/40 [00:50<?, ?it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 9:   2%|▎         | 1/40 [00:50<32:52, 50.59s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 9:   2%|▎         | 1/40 [01:40<32:52, 50.59s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 9:   5%|▌         | 2/40 [01:40<31:40, 50.01s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 9:   5%|▌         | 2/40 [02:29<31:40, 50.01s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 9:   8%|▊         | 3/40 [02:29<30:32, 49.52s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 9:   8%|▊         | 3/40 [03:23<30:32, 49.52s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 9:  10%|█         | 4/40 [03:23<30:55, 51.53s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 9:  10%|█         | 4/40 [04:13<30:55, 51.53s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 9:  12%|█▎        | 5/40 [04:13<29:35, 50.74s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 9:  12%|█▎        | 5/40 [05:02<29:35, 50.74s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 9:  15%|█▌        | 6/40 [05:02<28:32, 50.36s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 9:  15%|█▌        | 6/40 [05:54<28:32, 50.36s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 9:  18%|█▊        | 7/40 [05:54<27:52, 50.68s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 9:  18%|█▊        | 7/40 [06:45<27:52, 50.68s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 9:  20%|██        | 8/40 [06:45<27:14, 51.09s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 9:  20%|██        | 8/40 [07:35<27:14, 51.09s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 9:  22%|██▎       | 9/40 [07:35<26:09, 50.64s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 9:  22%|██▎       | 9/40 [08:25<26:09, 50.64s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 9:  25%|██▌       | 10/40 [08:25<25:08, 50.28s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 9:  25%|██▌       | 10/40 [09:14<25:08, 50.28s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 9:  28%|██▊       | 11/40 [09:14<24:06, 49.88s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 9:  28%|██▊       | 11/40 [10:03<24:06, 49.88s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 9:  30%|███       | 12/40 [10:03<23:09, 49.62s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 9:  30%|███       | 12/40 [10:52<23:09, 49.62s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 9:  32%|███▎      | 13/40 [10:52<22:15, 49.45s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 9:  32%|███▎      | 13/40 [11:41<22:15, 49.45s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 9:  35%|███▌      | 14/40 [11:41<21:22, 49.34s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 9:  35%|███▌      | 14/40 [12:30<21:22, 49.34s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 9:  38%|███▊      | 15/40 [12:30<20:31, 49.27s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 9:  38%|███▊      | 15/40 [13:20<20:31, 49.27s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 9:  40%|████      | 16/40 [13:20<19:46, 49.43s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 9:  40%|████      | 16/40 [14:10<19:46, 49.43s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 9:  42%|████▎     | 17/40 [14:10<19:01, 49.64s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 9:  42%|████▎     | 17/40 [15:00<19:01, 49.64s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 9:  45%|████▌     | 18/40 [15:00<18:13, 49.68s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 9:  45%|████▌     | 18/40 [15:50<18:13, 49.68s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 9:  48%|████▊     | 19/40 [15:50<17:26, 49.83s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 9:  48%|████▊     | 19/40 [16:39<17:26, 49.83s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 9:  50%|█████     | 20/40 [16:39<16:33, 49.67s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 9:  50%|█████     | 20/40 [17:28<16:33, 49.67s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 9:  52%|█████▎    | 21/40 [17:28<15:40, 49.47s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 9:  52%|█████▎    | 21/40 [18:17<15:40, 49.47s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 9:  55%|█████▌    | 22/40 [18:17<14:49, 49.42s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 9:  55%|█████▌    | 22/40 [19:07<14:49, 49.42s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 9:  57%|█████▊    | 23/40 [19:07<14:00, 49.47s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 9:  57%|█████▊    | 23/40 [19:57<14:00, 49.47s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 9:  60%|██████    | 24/40 [19:57<13:14, 49.66s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 9:  60%|██████    | 24/40 [20:47<13:14, 49.66s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 9:  62%|██████▎   | 25/40 [20:47<12:24, 49.62s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 9:  62%|██████▎   | 25/40 [21:35<12:24, 49.62s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 9:  65%|██████▌   | 26/40 [21:36<11:31, 49.40s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 9:  65%|██████▌   | 26/40 [22:24<11:31, 49.40s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 9:  68%|██████▊   | 27/40 [22:24<10:40, 49.28s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 9:  68%|██████▊   | 27/40 [23:14<10:40, 49.28s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 9:  70%|███████   | 28/40 [23:14<09:53, 49.44s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 9:  70%|███████   | 28/40 [24:03<09:53, 49.44s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 9:  72%|███████▎  | 29/40 [24:03<09:02, 49.28s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 9:  72%|███████▎  | 29/40 [24:53<09:02, 49.28s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 9:  75%|███████▌  | 30/40 [24:53<08:14, 49.42s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 9:  75%|███████▌  | 30/40 [25:43<08:14, 49.42s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 9:  78%|███████▊  | 31/40 [25:43<07:27, 49.71s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 9:  78%|███████▊  | 31/40 [26:35<07:27, 49.71s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 9:  80%|████████  | 32/40 [26:35<06:43, 50.45s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 9:  80%|████████  | 32/40 [27:26<06:43, 50.45s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 9:  82%|████████▎ | 33/40 [27:26<05:52, 50.32s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 9:  82%|████████▎ | 33/40 [28:16<05:52, 50.32s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 9:  85%|████████▌ | 34/40 [28:16<05:02, 50.43s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 9:  85%|████████▌ | 34/40 [29:06<05:02, 50.43s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 9:  88%|████████▊ | 35/40 [29:06<04:10, 50.11s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 9:  88%|████████▊ | 35/40 [29:56<04:10, 50.11s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 9:  90%|█████████ | 36/40 [29:56<03:20, 50.15s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 9:  90%|█████████ | 36/40 [30:47<03:20, 50.15s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 9:  92%|█████████▎| 37/40 [30:47<02:31, 50.48s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 9:  92%|█████████▎| 37/40 [31:37<02:31, 50.48s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 9:  95%|█████████▌| 38/40 [31:37<01:40, 50.32s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 9:  95%|█████████▌| 38/40 [32:27<01:40, 50.32s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 9:  98%|█████████▊| 39/40 [32:27<00:50, 50.19s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 9:  98%|█████████▊| 39/40 [32:43<00:50, 50.19s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 9: 100%|██████████| 40/40 [32:43<00:00, 39.97s/it, training_loss=0.132]\u001b[A\n",
            " 53%|█████▎    | 8/15 [5:13:48<4:04:39, 2097.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:17<01:44, 17.36s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:33<01:23, 16.64s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:49<01:05, 16.42s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [01:05<00:49, 16.34s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [01:22<00:33, 16.54s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [01:39<00:16, 16.64s/it]\u001b[A\n",
            "100%|██████████| 7/7 [01:55<00:00, 16.47s/it]\n",
            " 60%|██████    | 9/15 [5:15:43<3:29:11, 2091.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.5836420697825295\n",
            "F1 Score (weighted): 0.7836854247129267\n",
            "Accuracy: 0.8116591928251121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 10:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10:   0%|          | 0/40 [00:51<?, ?it/s, training_loss=0.024]\u001b[A\n",
            "Epoch 10:   2%|▎         | 1/40 [00:51<33:40, 51.81s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 10:   2%|▎         | 1/40 [01:46<33:40, 51.81s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 10:   5%|▌         | 2/40 [01:46<34:03, 53.78s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 10:   5%|▌         | 2/40 [02:36<34:03, 53.78s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 10:   8%|▊         | 3/40 [02:36<32:04, 52.02s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 10:   8%|▊         | 3/40 [03:26<32:04, 52.02s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 10:  10%|█         | 4/40 [03:26<30:40, 51.14s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 10:  10%|█         | 4/40 [04:15<30:40, 51.14s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 10:  12%|█▎        | 5/40 [04:15<29:22, 50.36s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 10:  12%|█▎        | 5/40 [05:05<29:22, 50.36s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 10:  15%|█▌        | 6/40 [05:05<28:22, 50.07s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 10:  15%|█▌        | 6/40 [05:55<28:22, 50.07s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 10:  18%|█▊        | 7/40 [05:55<27:30, 50.02s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 10:  18%|█▊        | 7/40 [06:44<27:30, 50.02s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 10:  20%|██        | 8/40 [06:44<26:33, 49.79s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 10:  20%|██        | 8/40 [07:33<26:33, 49.79s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 10:  22%|██▎       | 9/40 [07:33<25:38, 49.62s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 10:  22%|██▎       | 9/40 [08:22<25:38, 49.62s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 10:  25%|██▌       | 10/40 [08:22<24:42, 49.40s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 10:  25%|██▌       | 10/40 [09:11<24:42, 49.40s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 10:  28%|██▊       | 11/40 [09:11<23:48, 49.27s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 10:  28%|██▊       | 11/40 [10:02<23:48, 49.27s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 10:  30%|███       | 12/40 [10:02<23:10, 49.68s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 10:  30%|███       | 12/40 [10:52<23:10, 49.68s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 10:  32%|███▎      | 13/40 [10:52<22:29, 49.97s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 10:  32%|███▎      | 13/40 [11:43<22:29, 49.97s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 10:  35%|███▌      | 14/40 [11:43<21:48, 50.32s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 10:  35%|███▌      | 14/40 [12:33<21:48, 50.32s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 10:  38%|███▊      | 15/40 [12:33<20:56, 50.24s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 10:  38%|███▊      | 15/40 [13:23<20:56, 50.24s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 10:  40%|████      | 16/40 [13:23<20:00, 50.03s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 10:  40%|████      | 16/40 [14:12<20:00, 50.03s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 10:  42%|████▎     | 17/40 [14:12<19:06, 49.83s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 10:  42%|████▎     | 17/40 [15:02<19:06, 49.83s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 10:  45%|████▌     | 18/40 [15:02<18:13, 49.71s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 10:  45%|████▌     | 18/40 [15:52<18:13, 49.71s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 10:  48%|████▊     | 19/40 [15:52<17:29, 50.00s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 10:  48%|████▊     | 19/40 [16:43<17:29, 50.00s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 10:  50%|█████     | 20/40 [16:43<16:40, 50.05s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 10:  50%|█████     | 20/40 [17:32<16:40, 50.05s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 10:  52%|█████▎    | 21/40 [17:32<15:47, 49.89s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 10:  52%|█████▎    | 21/40 [18:22<15:47, 49.89s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 10:  55%|█████▌    | 22/40 [18:22<14:55, 49.75s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 10:  55%|█████▌    | 22/40 [19:11<14:55, 49.75s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 10:  57%|█████▊    | 23/40 [19:11<14:02, 49.55s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 10:  57%|█████▊    | 23/40 [20:00<14:02, 49.55s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 10:  60%|██████    | 24/40 [20:00<13:10, 49.38s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 10:  60%|██████    | 24/40 [20:49<13:10, 49.38s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 10:  62%|██████▎   | 25/40 [20:49<12:22, 49.50s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 10:  62%|██████▎   | 25/40 [21:39<12:22, 49.50s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 10:  65%|██████▌   | 26/40 [21:39<11:32, 49.44s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 10:  65%|██████▌   | 26/40 [22:28<11:32, 49.44s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 10:  68%|██████▊   | 27/40 [22:28<10:43, 49.53s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 10:  68%|██████▊   | 27/40 [23:19<10:43, 49.53s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 10:  70%|███████   | 28/40 [23:19<09:57, 49.76s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 10:  70%|███████   | 28/40 [24:08<09:57, 49.76s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 10:  72%|███████▎  | 29/40 [24:08<09:04, 49.53s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 10:  72%|███████▎  | 29/40 [24:57<09:04, 49.53s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 10:  75%|███████▌  | 30/40 [24:57<08:13, 49.35s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 10:  75%|███████▌  | 30/40 [25:46<08:13, 49.35s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 10:  78%|███████▊  | 31/40 [25:46<07:23, 49.23s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 10:  78%|███████▊  | 31/40 [26:35<07:23, 49.23s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 10:  80%|████████  | 32/40 [26:35<06:33, 49.23s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 10:  80%|████████  | 32/40 [27:24<06:33, 49.23s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 10:  82%|████████▎ | 33/40 [27:24<05:44, 49.22s/it, training_loss=0.095]\u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runtime got disconnected after 9th epoch.So, i am considering the parameters in 8th epoch. Finally we have achieved an accuracy of 82%. \n",
        "\n",
        "To imporve the model performance further, we can add some extra layers on top of bert."
      ],
      "metadata": {
        "id": "ZWnNoRN1YoRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/My Drive/Models/BERT_ft_epoch8.model'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwGDjtehFLJl",
        "outputId": "d2a9dd25-0843-458f-f15b-ce8768c5d353"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF6GCAKbsd2AiexzLakQb+"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "517f03be6bdf4382b7325af067f03095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aeb277b0a468411ebe68467f2ff9a1a1",
              "IPY_MODEL_11cb67bc93a5486680b51372fb96631b",
              "IPY_MODEL_5475d40da5574109bcbce21dc7b9dbcc"
            ],
            "layout": "IPY_MODEL_694d4be1e3be4e1eb336062b4e676565"
          }
        },
        "aeb277b0a468411ebe68467f2ff9a1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3846a642f5b04b4f8c50602e390a3507",
            "placeholder": "​",
            "style": "IPY_MODEL_a4851168826749dda36cad08346003ed",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "11cb67bc93a5486680b51372fb96631b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e04e08b88489446da8c10212427d4259",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_741d668d5af646d8b9841db4304e3ac9",
            "value": 231508
          }
        },
        "5475d40da5574109bcbce21dc7b9dbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9cd3a57db4b49e68efd73b139f34e64",
            "placeholder": "​",
            "style": "IPY_MODEL_48693750f21a48e2bbbaa9ade64819aa",
            "value": " 232k/232k [00:00&lt;00:00, 311kB/s]"
          }
        },
        "694d4be1e3be4e1eb336062b4e676565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3846a642f5b04b4f8c50602e390a3507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4851168826749dda36cad08346003ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e04e08b88489446da8c10212427d4259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "741d668d5af646d8b9841db4304e3ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9cd3a57db4b49e68efd73b139f34e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48693750f21a48e2bbbaa9ade64819aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c217671ff8784a4ca0867a5092da65c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19be41747ace43d39791995371158713",
              "IPY_MODEL_102ec675ca724201a81435d0fba7a3b1",
              "IPY_MODEL_b686b6d1ca024c21be675fece5266c5c"
            ],
            "layout": "IPY_MODEL_3bbe7904d219443495dd227308807acc"
          }
        },
        "19be41747ace43d39791995371158713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c4c17a2a71340e2a0056537b3af3b01",
            "placeholder": "​",
            "style": "IPY_MODEL_0b9ee6800dfd462bb5c657b5c771abeb",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "102ec675ca724201a81435d0fba7a3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49882b71eb36414ca52085ba38faa974",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51b99209b92a465d96ea12c53725a865",
            "value": 28
          }
        },
        "b686b6d1ca024c21be675fece5266c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de234455d29f4ca69e8c292afd46029d",
            "placeholder": "​",
            "style": "IPY_MODEL_0abe55b53ccf447993beacf3f62ca3a8",
            "value": " 28.0/28.0 [00:00&lt;00:00, 345B/s]"
          }
        },
        "3bbe7904d219443495dd227308807acc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c4c17a2a71340e2a0056537b3af3b01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9ee6800dfd462bb5c657b5c771abeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49882b71eb36414ca52085ba38faa974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b99209b92a465d96ea12c53725a865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de234455d29f4ca69e8c292afd46029d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0abe55b53ccf447993beacf3f62ca3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a61b09279d04bdc8bfcc7e87abe0d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf5cef01a7de419d9e97f7400a0fb610",
              "IPY_MODEL_8d163c6a61e745689d4f4fa7b57b824e",
              "IPY_MODEL_35250e5ffdba410a963ea8612f4f975c"
            ],
            "layout": "IPY_MODEL_20edcf7373614fb88f6f72118e9a30dd"
          }
        },
        "cf5cef01a7de419d9e97f7400a0fb610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76772e92545249049b993d4f9641222d",
            "placeholder": "​",
            "style": "IPY_MODEL_a52760ae46a443cfaa9906bbd89d0cd2",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "8d163c6a61e745689d4f4fa7b57b824e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ebee49612664caebe1d2abe10fe060b",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7836127dc99f41f5acb83cc374180443",
            "value": 570
          }
        },
        "35250e5ffdba410a963ea8612f4f975c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6434c36dacad465e98acbdacfea6fc3b",
            "placeholder": "​",
            "style": "IPY_MODEL_5e1c048712824450871003f91c4da64a",
            "value": " 570/570 [00:00&lt;00:00, 9.02kB/s]"
          }
        },
        "20edcf7373614fb88f6f72118e9a30dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76772e92545249049b993d4f9641222d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a52760ae46a443cfaa9906bbd89d0cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ebee49612664caebe1d2abe10fe060b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7836127dc99f41f5acb83cc374180443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6434c36dacad465e98acbdacfea6fc3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e1c048712824450871003f91c4da64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2658a673f7ac4e0e9e428f991e0098dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_351ff803c41544698318511eb4f4793a",
              "IPY_MODEL_b2b7eca3afad49bc88f40eeade756fde",
              "IPY_MODEL_4c9f2554174741ed9c5e60cac749e280"
            ],
            "layout": "IPY_MODEL_e6ba7d9a354e4ab69e5c088c539225c2"
          }
        },
        "351ff803c41544698318511eb4f4793a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9ff622d35764c04bb0df0998c3657d1",
            "placeholder": "​",
            "style": "IPY_MODEL_1638dec07bc749b1873f172bd4997f2f",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "b2b7eca3afad49bc88f40eeade756fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_356ca675e29d43f683f2042f348d8be4",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00b49bead3294e15b2d1c46053f54281",
            "value": 440473133
          }
        },
        "4c9f2554174741ed9c5e60cac749e280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_860d8497bf854b8c8a2da5bb6784af73",
            "placeholder": "​",
            "style": "IPY_MODEL_667365311e614240841facd850681195",
            "value": " 440M/440M [00:05&lt;00:00, 88.6MB/s]"
          }
        },
        "e6ba7d9a354e4ab69e5c088c539225c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ff622d35764c04bb0df0998c3657d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1638dec07bc749b1873f172bd4997f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "356ca675e29d43f683f2042f348d8be4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b49bead3294e15b2d1c46053f54281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "860d8497bf854b8c8a2da5bb6784af73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667365311e614240841facd850681195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}